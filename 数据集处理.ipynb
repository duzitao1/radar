{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置参数\n",
    "配置的参数,需要与采集数据时雷达配置的参数一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from RealTimeCollector.RealTimeCollector import RealTimeCollector\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "n_RX = 4  # RX天线通道总数\n",
    "n_samples = 64  # 采样点数\n",
    "n_chirps = 255  # 每帧脉冲数\n",
    "N = 64  # 距离向FFT点数\n",
    "M = 64  # 多普勒向FFT点数\n",
    "Q = 64  # 角度FFT\n",
    "\n",
    "c = 3.0e8   # 光速\n",
    "B = 3999.48e6  # 调频带宽\n",
    "K = 99.987e12  # 调频斜率\n",
    "T = B / K  # 调频周期\n",
    "Tc = 140e-6  # chirp总周期\n",
    "fs = 2.5e6  # 采样率\n",
    "f0 = 77e9  # 初始频率\n",
    "lambda_val = c / f0  # 雷达信号波长\n",
    "d = lambda_val / 2  # 天线阵列间距\n",
    "\n",
    "numADCBits = 16 # ADC位数\n",
    "numLanes = 4    # 通道数\n",
    "isReal = 0      # 是否为实数\n",
    "\n",
    "# 是否静态杂波滤除\n",
    "is_static_clutter_removal = 1\n",
    "\n",
    "num_classes = 5 # 类别数\n",
    "num_samples = 1600\n",
    "n_frames = 30\n",
    "\n",
    "distance_axis = torch.arange(0, N) * fs * c / (2 * K * N)   # 距离轴\n",
    "velocity_axis = torch.arange(-M/2, M/2) * lambda_val / Tc / M / 2   # 速度轴\n",
    "\n",
    "rtc = RealTimeCollector(ip_address='127.0.0.50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前类别为：1\n",
      "当前类别为：2\n",
      "当前类别为：3\n",
      "当前类别为：4\n"
     ]
    }
   ],
   "source": [
    "# 从指定文件夹中随机复制指定数量的文件到目标文件夹\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "\n",
    "def copy_random_files(source_path, target_path, class_list, num_files_per_class,cnt=0):\n",
    "\n",
    "    # 创建目标类别文件夹\n",
    "    target_dir = os.path.join(target_path, '9')\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # 遍历指定的类别\n",
    "    for label in class_list:\n",
    "        print(f'当前类别为：{label}')\n",
    "        source_dir = os.path.join(source_path, str(label))\n",
    "\n",
    "        bin_files = sorted(glob.glob(os.path.join(source_dir, '*.bin')))\n",
    "\n",
    "        # 随机抽取指定数量的文件\n",
    "        random_files = random.sample(bin_files, num_files_per_class)\n",
    "\n",
    "        # 复制文件到目标文件夹并重命名\n",
    "        for i, file in enumerate(random_files):\n",
    "            cnt += 1\n",
    "            shutil.copy(file, os.path.join(target_dir, f'{cnt}.bin'))\n",
    "\n",
    "# 使用示例\n",
    "source_path = 'K:/dataset/2023_12_7/'\n",
    "target_path = 'K:/temp/AA/'\n",
    "class_list = [5, 6, 7, 8]  # 需要提取的类别列表\n",
    "num_files_per_class = 200  # 每个类别随机复制200个文件\n",
    "copy_random_files(source_path, target_path, class_list, num_files_per_class, cnt=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:/dataset/1000\\1\n"
     ]
    }
   ],
   "source": [
    "# 将指定文件夹下的所有文件夹中的所有.bin文件重命名为1到n_samples,并删除.txt和.csv文件\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def rename_and_remove_files(file_path, num_classes):\n",
    "    for clss in range(1, num_classes + 1):\n",
    "        file_dir = os.path.join(file_path, str(clss))\n",
    "        print(file_dir)\n",
    "\n",
    "        # 获取目录下所有文件名\n",
    "        all_files = sorted(os.listdir(file_dir))\n",
    "\n",
    "        # 重命名.bin文件\n",
    "        cnt_bin = 1\n",
    "        for file_name in all_files:\n",
    "            file_path_old = os.path.join(file_dir, file_name)\n",
    "            file_extension = os.path.splitext(file_name)[1]\n",
    "\n",
    "            if file_extension == '.bin':\n",
    "                file_name_new = f'{cnt_bin}.bin'\n",
    "                file_path_new = os.path.join(file_dir, file_name_new)\n",
    "\n",
    "                # 如果新的文件名已存在，则加上序号后缀\n",
    "                while os.path.exists(file_path_new):\n",
    "                    cnt_bin += 1\n",
    "                    file_name_new = f'{cnt_bin}.bin'\n",
    "                    file_path_new = os.path.join(file_dir, file_name_new)\n",
    "\n",
    "                os.rename(file_path_old, file_path_new)\n",
    "                cnt_bin += 1\n",
    "\n",
    "        # 删除.txt和.csv文件\n",
    "        for file_name in all_files:\n",
    "            file_path = os.path.join(file_dir, file_name)\n",
    "            file_extension = os.path.splitext(file_name)[1]\n",
    "\n",
    "            if file_extension in ['.txt', '.csv']:\n",
    "                os.remove(file_path)\n",
    "\n",
    "file_path = 'K:/dataset/1000'\n",
    "num_classes = 1  # 假设有10个类别\n",
    "rename_and_remove_files(file_path, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于合并多个.mat文件\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "def load_mat_files(input_path):\n",
    "    data = sio.loadmat(input_path)\n",
    "    range_profile = data['range_profile']\n",
    "    speed_profile = data['speed_profile']\n",
    "    angle_profile = data['angle_profile']\n",
    "    return range_profile, speed_profile, angle_profile\n",
    "\n",
    "# 定义合并.mat文件的函数\n",
    "def merge_mat_files(input_path_list, output_path):\n",
    "    range_profile = []\n",
    "    speed_profile = []\n",
    "    angle_profile = []\n",
    "    \n",
    "    for input_path in input_path_list:\n",
    "        range_profile_, speed_profile_, angle_profile_ = load_mat_files(input_path)\n",
    "        range_profile.append(range_profile_)\n",
    "        speed_profile.append(speed_profile_)\n",
    "        angle_profile.append(angle_profile_)\n",
    "    \n",
    "    range_profile = np.concatenate(range_profile, axis=0)\n",
    "    speed_profile = np.concatenate(speed_profile, axis=0)\n",
    "    angle_profile = np.concatenate(angle_profile, axis=0)\n",
    "    \n",
    "    \n",
    "    sio.savemat(output_path, {'range_profile': range_profile, 'speed_profile': speed_profile, 'angle_profile': angle_profile})\n",
    "\n",
    "# 定义合并数据集的函数\n",
    "def merge_datasets(input_path_list, output_path, num_classes):\n",
    "    for i in range(1, num_classes+1):\n",
    "        input_path = [os.path.join(path, str(i)+'.mat') for path in input_path_list]\n",
    "        merge_mat_files(input_path, os.path.join(output_path, f'{i}.mat'))\n",
    "\n",
    "input_path_list = ['K:/aio_radar/out/1000/avg_remove', 'K:/aio_radar/out/1000/avg']\n",
    "out_path = 'K:/aio_radar/out/1000/test'\n",
    "merge_datasets(input_path_list, out_path, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
